{"cells":[{"cell_type":"markdown","metadata":{"id":"CYXY0OeORN45"},"source":["# OpenAI API 사전 준비"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aEJ8Sf3fRV2Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719294035079,"user_tz":-540,"elapsed":9476,"user":{"displayName":"Haneol Choi","userId":"07324773000759146887"}},"outputId":"1204c9ed-7415-4146-fc8f-be666838d8a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.0)\n","Collecting openai\n","  Downloading openai-1.35.3-py3-none-any.whl (327 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n","Installing collected packages: h11, httpcore, httpx, openai\n","  Attempting uninstall: openai\n","    Found existing installation: openai 0.28.0\n","    Uninstalling openai-0.28.0:\n","      Successfully uninstalled openai-0.28.0\n","Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.3\n"]}],"source":["# 패키지 설치\n","!pip install openai --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9TMp1p0RWBM"},"outputs":[],"source":["# 환경변수 준비\n","import os\n","os.environ[\"OPENAI_API_KEY\"] = \"\""]},{"cell_type":"markdown","metadata":{"id":"E9URF8m_RS1j"},"source":["# 학습 데이터 준비"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GD-FmSEz05dH","executionInfo":{"status":"ok","timestamp":1719294057803,"user_tz":-540,"elapsed":2521,"user":{"displayName":"Haneol Choi","userId":"07324773000759146887"}},"outputId":"b7ac8428-3649-4aa6-d8b3-f54f38f6e98c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wXwC3looO0a9"},"outputs":[],"source":["import pandas as pd\n","\n","# 데이터 세트 준비\n","df = pd.read_csv(\n","    'tsukuyomi1.csv',\n","    usecols=[1,2],\n","    names=['prompt','completion'],\n","    skiprows=2)\n","df.to_json(\n","    \"tsukuyomi.jsonl\",\n","    orient='records',\n","    lines=True,\n","    force_ascii=False\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LSWAS0pJRaug","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719297077135,"user_tz":-540,"elapsed":2579,"user":{"displayName":"Haneol Choi","userId":"07324773000759146887"}},"outputId":"da471c78-c802-4f3a-961f-33a6f3709182"},"outputs":[{"output_type":"stream","name":"stdout","text":["Analyzing...\n","\n","- Your file contains 432 prompt-completion pairs\n","- More than a third of your `prompt` column/key is uppercase. Uppercase prompts tends to perform worse than a mixture of case encountered in normal language. We recommend to lower case the data if that makes sense in your domain. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n","- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n","- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n","- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n","\n","Based on the analysis we will perform the following actions:\n","- [Recommended] Lowercase all your data in column/key `prompt` [Y/n]: Y\n","- [Recommended] Add a suffix separator `\\n\\n###\\n\\n` to all prompts [Y/n]: Y\n","- [Recommended] Add a suffix ending `\\n` to all completions [Y/n]: Y\n","- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n","\n","\n","Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n","\n","Wrote modified file to `tsukuyomi_prepared (1).jsonl`\n","Feel free to take a look!\n","\n","Now use that file when fine-tuning:\n","> openai api fine_tunes.create -t \"tsukuyomi_prepared (1).jsonl\"\n","\n","After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n\"]` so that the generated texts ends at the expected place.\n","Once your model starts training, it'll approximately take 8.38 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"]}],"source":["# 데이터 세트 검증\n","!openai tools fine_tunes.prepare_data \\\n","    -f tsukuyomi.jsonl \\\n","    -q"]},{"cell_type":"code","source":["! pip install tiktoken"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AHTFP9LkF276","executionInfo":{"status":"ok","timestamp":1719297099403,"user_tz":-540,"elapsed":6930,"user":{"displayName":"Haneol Choi","userId":"07324773000759146887"}},"outputId":"89587584-69d5-4b0a-b852-7e23c3d2c46b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tiktoken\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n","Installing collected packages: tiktoken\n","Successfully installed tiktoken-0.7.0\n"]}]},{"cell_type":"code","source":["import json\n","import tiktoken # for token counting\n","import numpy as np\n","from collections import defaultdict\n","\n","data_path = \"tsukuyomi.jsonl\"\n","\n","# Load the dataset\n","with open(data_path, 'r', encoding='utf-8') as f:\n","    dataset = [json.loads(line) for line in f]\n","\n","# Initial dataset stats\n","print(\"Num examples:\", len(dataset))\n","print(\"First example:\")\n","for message in dataset[0][\"prompt\"]:\n","    print(message)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vn0dzCaaFt3K","executionInfo":{"status":"ok","timestamp":1719297139504,"user_tz":-540,"elapsed":536,"user":{"displayName":"Haneol Choi","userId":"07324773000759146887"}},"outputId":"9c8201a6-c7fd-477b-bbcd-c9ae07c7afca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num examples: 432\n","First example:\n","배\n","가\n"," \n","고\n","프\n","다\n"]}]},{"cell_type":"code","source":["# dataset[0]"],"metadata":{"id":"2HLW9OTwGiUx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Format error checks\n","# format_errors = defaultdict(int)\n","\n","# for ex in dataset:\n","#     if not isinstance(ex, dict):\n","#         format_errors[\"data_type\"] += 1\n","#         continue\n","\n","#     messages = ex.get(\"messages\", None)\n","#     if not messages:\n","#         format_errors[\"missing_messages_list\"] += 1\n","#         continue\n","\n","#     for message in messages:\n","#         if \"role\" not in message or \"content\" not in message:\n","#             format_errors[\"message_missing_key\"] += 1\n","\n","#         if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n","#             format_errors[\"message_unrecognized_key\"] += 1\n","\n","#         if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n","#             format_errors[\"unrecognized_role\"] += 1\n","\n","#         content = message.get(\"content\", None)\n","#         function_call = message.get(\"function_call\", None)\n","\n","#         if (not content and not function_call) or not isinstance(content, str):\n","#             format_errors[\"missing_content\"] += 1\n","\n","#     if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n","#         format_errors[\"example_missing_assistant_message\"] += 1\n","\n","# if format_errors:\n","#     print(\"Found errors:\")\n","#     for k, v in format_errors.items():\n","#         print(f\"{k}: {v}\")\n","# else:\n","#     print(\"No errors found\")"],"metadata":{"id":"BFEtvNweGIsB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mOACk5n3Y8EW"},"source":["# 파인튜닝 실행"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G9w3Rj3SRawk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719299197584,"user_tz":-540,"elapsed":1629,"user":{"displayName":"Haneol Choi","userId":"07324773000759146887"}},"outputId":"c921cebf-47b4-4ba7-e6d3-99bcae204759"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["FileObject(id='file-aXYQP9CuJueXPLcsxd09b5H8', bytes=64228, created_at=1719299196, filename='tsukuyomi.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"]},"metadata":{},"execution_count":69}],"source":["# # 파인튜닝 수행\n","# !openai api fine_tunes.create \\\n","#     -t \"tsukuyomi_prepared.jsonl\" \\\n","#     -m davinci\n","\n","from openai import OpenAI\n","client = OpenAI()\n","\n","client.files.create(\n","  file=open(\"tsukuyomi_prepared.jsonl\", \"rb\"),\n","  purpose=\"fine-tune\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kEH_mWCmrGCN"},"outputs":[],"source":["# # 파인튜닝 작업 상태 확인\n","# !openai api fine_tunes.get \\\n","#     -i ft-ElEoXDioUUTHHm3lxUmYIr2D"]},{"cell_type":"code","source":["from openai import OpenAI\n","client = OpenAI()\n","\n","client.fine_tuning.jobs.create(\n","  training_file=\"file-P9uyfMG1AvVJ1VkW9v1Ao9cV\",\n","  model=\"davinci-002\"\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0foflA556j3j","executionInfo":{"status":"ok","timestamp":1719299212029,"user_tz":-540,"elapsed":2875,"user":{"displayName":"Haneol Choi","userId":"07324773000759146887"}},"outputId":"80238884-4370-4695-ac52-b0120d00180a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["FineTuningJob(id='ftjob-Ky4XNjL8x3hutiqKq2L5R6U2', created_at=1719299211, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='davinci-002', object='fine_tuning.job', organization_id='org-PLIHvIZaN5qBCns42JU7An4M', result_files=[], seed=1191957944, status='validating_files', trained_tokens=None, training_file='file-aXYQP9CuJueXPLcsxd09b5H8', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["# from openai import OpenAI\n","# client = OpenAI()\n","\n","# # List 10 fine-tuning jobs\n","# # client.fine_tuning.jobs.list(limit=10)\n","\n","# # # Retrieve the state of a fine-tune\n","# # client.fine_tuning.jobs.retrieve(\"ftjob-abc123\")\n","\n","# # # Cancel a job\n","# # client.fine_tuning.jobs.cancel(\"ftjob-abc123\")\n","\n","# # List up to 10 events from a fine-tuning job\n","# client.fine_tuning.jobs.list_events(fine_tuning_job_id=\"ftjob-x6ulc4zBad6Q9QuckoiS2HgR\", limit=10)\n","\n","# # Delete a fine-tuned model (must be an owner of the org the model was created in)\n","# # client.models.delete(\"ft:gpt-3.5-turbo:acemeco:suffix:abc123\")"],"metadata":{"id":"FcvKJ112An6S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !curl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F \\\n","#   -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"],"metadata":{"id":"HeKcchpsDNLK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W3DkzRg8Y5Yd"},"source":["# 추론 실행"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1n1VjSYPRa2k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719300517058,"user_tz":-540,"elapsed":1046,"user":{"displayName":"Haneol Choi","userId":"07324773000759146887"}},"outputId":"44001e3e-7039-4820-80f4-ec64ac9b06db"},"outputs":[{"output_type":"stream","name":"stdout","text":[" 그림에 그린 떡입니다!\n"]}],"source":["# import openai\n","\n","# # 추론 실행\n","prompt=\"좋아하는 음식은 무엇인가요? ->\"\n","# response = openai.Completion.create(\n","#     model=\"ft:gpt-3.5-turbo-0125\",\n","#     prompt=prompt,\n","#     max_tokens=100,\n","#     stop=\"\\n\")\n","# print(response[\"choices\"][0][\"text\"])\n","\n","from openai import OpenAI\n","client = OpenAI()\n","\n","completion = openai.completions.create(\n","  model=\"ft:davinci-002:personal::9duGTZF0\",\n","  prompt=prompt,\n","  max_tokens=100,\n","  stop=\"\\n\"\n",")\n","# print(completion[\"text\"])\n","# print(completion[\"choices\"])\n","# print(completion.choices[0])\n","print(completion.choices[0].text)\n"]},{"cell_type":"markdown","metadata":{"id":"iREq-C5Qy_OX"},"source":["# 파인튜닝 모델 목록 조회 및 삭제"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J5hsC4zQi2Zr"},"outputs":[],"source":["# 파인튜닝 모델 목록 보기\n","!openai api fine_tunes.list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"26KZISYSYSeF"},"outputs":[],"source":["# 파인튜닝 모델 삭제\n","!openai api models.delete \\\n","    -i <모델 ID>"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}