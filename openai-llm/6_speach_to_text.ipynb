{"cells":[{"cell_type":"markdown","metadata":{"id":"gZEzRfryU2Gb"},"source":["# OpenAI API 사전 준비"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mkPbwp6-ploX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719298457589,"user_tz":-540,"elapsed":16915,"user":{"displayName":"Haneol Choi","userId":"07324773000759146887"}},"outputId":"7bcbe6cd-4c0e-461d-fc52-be9193c11ac2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai==0.28\n","  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.6.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n","Installing collected packages: openai\n","Successfully installed openai-0.28.0\n"]}],"source":["# 패키지 설치\n","!pip install openai==0.28"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Gf8Rfw2MiG_"},"outputs":[],"source":["# 환경변수 준비\n","import os\n","os.environ[\"OPENAI_API_KEY\"] = \"\""]},{"cell_type":"markdown","metadata":{"id":"m8livzxDU6cQ"},"source":["# 음성 텍스트 변환"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UEjUkZfDLDwS","executionInfo":{"status":"ok","timestamp":1719298823414,"user_tz":-540,"elapsed":8583,"user":{"displayName":"Haneol Choi","userId":"07324773000759146887"}},"outputId":"e0ffbe6a-dd39-4466-e4bd-6e3fbed74d5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E1_g9k-1Zr9j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719299119505,"user_tz":-540,"elapsed":2248,"user":{"displayName":"Haneol Choi","userId":"07324773000759146887"}},"outputId":"08a5efb9-cea5-455b-f904-8e3eeb43e1da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Whisper는 범위온 음성인식 모델입니다. 다양한 오디오의 대규모 데이터 시트를 학습하고 다국어 음성인식, 음성번역, 언어식별을 수행할 수 있는 멀티태스킹 모델이기도 합니다.\n"]}],"source":["import openai\n","\n","# 음성 텍스트 변환(현재 폴더에 오디오 파일을 업로드해두세요)\n","audio_file= open(\"audio.mp3\", \"rb\")\n","transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n","print(transcript[\"text\"])"]},{"cell_type":"markdown","metadata":{"id":"-T4r7xVoXAdc"},"source":[" # 음성을 영어로 번역해서 텍스트로 변환하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ACl657swXCwV"},"outputs":[],"source":["import openai\n","\n","# 음성을 영어로 번역하고 텍스트로 변환(현재 폴더에 오디오 파일을 업로드해둡니다)\n","audio_file= open(\"/content/drive/MyDrive/Colab Notebooks/배울랑교(llm)/openai-llm-main/openai-llm-main/4_openai_api/audio.mp3\", \"rb\")\n","transcript = openai.Audio.translate(\"whisper-1\", audio_file)"]},{"cell_type":"code","source":["print(transcript[\"text\"])"],"metadata":{"id":"M4isHLggOqLR","executionInfo":{"status":"ok","timestamp":1719299385968,"user_tz":-540,"elapsed":3,"user":{"displayName":"Haneol Choi","userId":"07324773000759146887"}},"outputId":"1e69a01a-7ac7-4b7a-95ee-c994398c574c","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Whisper is a multi-tasking model that can learn a large set of audio data sets and perform multi-language voice recognition, voice translation, and language recognition.\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}